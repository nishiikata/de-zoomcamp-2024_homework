{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 Homework \n",
    "\n",
    "In this homework we'll put what we learned about Spark in practice.\n",
    "\n",
    "For this homework we will be using the FHV 2019-10 data found here. [FHV Data](https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: \n",
    "\n",
    "**Install Spark and PySpark** \n",
    "\n",
    "- Install Spark\n",
    "- Run PySpark\n",
    "- Create a local spark session\n",
    "- Execute spark.version.\n",
    "\n",
    "What's the output?\n",
    "\n",
    "> [!NOTE]\n",
    "> To install PySpark follow this [guide](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/05-batch/setup/pyspark.md)\n",
    "\n",
    "### Notes:\n",
    "\n",
    ":white_check_mark: '3.5.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from typing import TYPE_CHECKING\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import max\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: \n",
    "\n",
    "**FHV October 2019**\n",
    "\n",
    "Read the October 2019 FHV into a Spark Dataframe with a schema as we did in the lessons.\n",
    "\n",
    "Repartition the Dataframe to 6 partitions and save it to parquet.\n",
    "\n",
    "What is the average size of the Parquet (ending with .parquet extension) Files that were created (in MB)? Select the answer which most closely matches.\n",
    "\n",
    "- 1MB\n",
    "- 6MB\n",
    "- 25MB\n",
    "- 87MB\n",
    "\n",
    "### Notes:\n",
    "\n",
    ":white_check_mark: 6MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File 'fhv_tripdata_2019-10.csv.gz' already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('dispatching_base_num', StringType()),\n",
    "    StructField('pickup_datetime', TimestampType()),\n",
    "    StructField('dropOff_datetime', TimestampType()),\n",
    "    StructField('PUlocationID', ShortType()),\n",
    "    StructField('DOlocationID', ShortType()),\n",
    "    StructField('SR_Flag', FloatType()),\n",
    "    StructField('Affiliated_base_number', StringType()),\n",
    "])\n",
    "(spark.read\n",
    "    .csv(\n",
    "        \"./fhv_tripdata_2019-10.csv.gz\",\n",
    "        header=True,\n",
    "        schema=schema,\n",
    "    )\n",
    "    .repartition(6)\n",
    "    .write\n",
    "    .parquet(\"./fhv_tripdata_2019-10/\", mode=\"overwrite\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2 Answer: The average size of parquet files is 6.36 MB\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "root_directory = Path(\"./fhv_tripdata_2019-10/\")\n",
    "pq_sizes_bytes: list[int] = [f.stat().st_size for f in root_directory.glob(\"*.parquet\") if f.is_file()]\n",
    "\n",
    "pq_mean_size_bytes: int = statistics.fmean(pq_sizes_bytes)\n",
    "pq_mean_size_megabytes: int = pq_mean_size_bytes / (1024 * 1024)\n",
    "print(\"Q2 Answer: The average size of parquet files is {:.2f} MB\".format(pq_mean_size_megabytes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: \n",
    "\n",
    "**Count records** \n",
    "\n",
    "How many taxi trips were there on the 15th of October?\n",
    "\n",
    "Consider only trips that started on the 15th of October.\n",
    "\n",
    "- 108,164\n",
    "- 12,856\n",
    "- 452,470\n",
    "- 62,610\n",
    "\n",
    "> [!IMPORTANT]\n",
    "> Be aware of columns order when defining schema\n",
    "\n",
    "### Notes:\n",
    "\n",
    ":white_check_mark: 62,610"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B02111|2019-10-27 05:35:21|2019-10-27 05:38:04|          92|          80|   NULL|                B02111|\n",
      "|              B01437|2019-10-08 09:41:27|2019-10-08 09:46:52|         264|         197|   NULL|                B01437|\n",
      "|              B02107|2019-10-09 16:53:55|2019-10-09 17:06:05|         264|         167|   NULL|                B02107|\n",
      "|              B01653|2019-10-15 06:47:13|2019-10-15 06:59:36|         264|         264|   NULL|                B01653|\n",
      "|              B00850|2019-10-13 03:57:31|2019-10-13 04:12:36|         264|         177|   NULL|                B00850|\n",
      "|              B00756|2019-10-08 23:21:00|2019-10-08 23:37:00|         264|         264|   NULL|                B00756|\n",
      "|              B01145|2019-10-23 20:25:35|2019-10-23 20:38:18|         264|         147|   NULL|                B02971|\n",
      "|              B01854|2019-10-09 18:15:00|2019-10-09 18:36:00|         264|         264|   NULL|                B02883|\n",
      "|     B01467         |2019-10-19 13:45:55|2019-10-19 13:55:45|         146|           7|   NULL|       B02925         |\n",
      "|              B01854|2019-10-17 14:15:00|2019-10-17 14:37:00|         264|         264|   NULL|                B02869|\n",
      "|              B00310|2019-10-26 16:28:44|2019-10-26 16:45:48|         264|          20|   NULL|                B00310|\n",
      "|              B01984|2019-10-23 09:22:00|2019-10-23 09:39:00|         264|          95|   NULL|                B01984|\n",
      "|              B03033|2019-10-02 10:23:27|2019-10-02 10:32:26|         264|          36|   NULL|                B03033|\n",
      "|              B03016|2019-10-28 12:46:13|2019-10-28 13:38:36|         264|         265|   NULL|                B03016|\n",
      "|              B00477|2019-10-31 23:18:39|2019-10-31 23:49:37|         162|         264|   NULL|                B00477|\n",
      "|              B01710|2019-10-03 09:46:40|2019-10-03 10:19:05|         264|         264|   NULL|                B01710|\n",
      "|              B01525|2019-10-15 09:43:01|2019-10-15 10:24:45|         264|          71|   NULL|                B01525|\n",
      "|              B01751|2019-10-03 14:44:13|2019-10-03 15:35:17|         264|         264|   NULL|                B01751|\n",
      "|              B02429|2019-10-31 06:24:04|2019-10-31 06:50:02|         264|         264|   NULL|                B02429|\n",
      "|              B01145|2019-10-20 18:59:57|2019-10-20 19:02:57|         264|         259|   NULL|                B02877|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if TYPE_CHECKING:\n",
    "    from pyspark.sql import DataFrame\n",
    "\n",
    "\n",
    "fhv: \"DataFrame\" = spark.read.parquet(\"./fhv_tripdata_2019-10/\")\n",
    "fhv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3 Answer: There were 62,610 taxi trips on the 15th of October\n"
     ]
    }
   ],
   "source": [
    "trip_count: int = fhv.where(\"cast(pickup_datetime as date) = '2019-10-15'\").count()\n",
    "print(\"Q3 Answer: There were {:,} taxi trips on the 15th of October\".format(trip_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: \n",
    "\n",
    "**Longest trip for each day** \n",
    "\n",
    "What is the length of the longest trip in the dataset in hours?\n",
    "\n",
    "- 631,152.50 Hours\n",
    "- 243.44 Hours\n",
    "- 7.68 Hours\n",
    "- 3.32 Hours\n",
    "\n",
    "### Notes:\n",
    "\n",
    ":white_check_mark: 631,152.50 Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4 Answer: The length of the longest trip in the dataset is 631,152.50 hours\n"
     ]
    }
   ],
   "source": [
    "if TYPE_CHECKING:\n",
    "    from datetime import timedelta\n",
    "\n",
    "\n",
    "td: \"timedelta\" = (fhv.select(max(fhv.dropOff_datetime - fhv.pickup_datetime))\n",
    "    .first()[0]\n",
    ")\n",
    "longest_trip_in_hours: int = td.days * 24 + (td.seconds + td.microseconds * 1e-6) / (60 * 60)\n",
    "print(\"Q4 Answer: The length of the longest trip in the dataset is {:,.2f} hours\".format(longest_trip_in_hours))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: \n",
    "\n",
    "**User Interface**\n",
    "\n",
    "Spark’s User Interface which shows the application's dashboard runs on which local port?\n",
    "\n",
    "- 80\n",
    "- 443\n",
    "- 4040\n",
    "- 8080\n",
    "\n",
    "### Notes:\n",
    "\n",
    ":white_check_mark: 4040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=test>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'http://host.docker.internal:4040'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(display(spark.sparkContext))\n",
    "spark.sparkContext.uiWebUrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6: \n",
    "\n",
    "**Least frequent pickup location zone**\n",
    "\n",
    "Load the zone lookup data into a temp view in Spark</br>\n",
    "[Zone Data](https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv)\n",
    "\n",
    "Using the zone lookup data and the FHV October 2019 data, what is the name of the LEAST frequent pickup location Zone?</br>\n",
    "\n",
    "- East Chelsea\n",
    "- Jamaica Bay\n",
    "- Union Sq\n",
    "- Crown Heights North\n",
    "\n",
    "### Notes:\n",
    "\n",
    ":white_check_mark: Jamaica Bay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File 'taxi_zone_lookup.csv' already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField('LocationID', ShortType()),\n",
    "    StructField('Borough', StringType()),\n",
    "    StructField('Zone', StringType()),\n",
    "    StructField('service_zone', StringType()),\n",
    "])\n",
    "(spark.read\n",
    "    .csv(\n",
    "        \"./taxi_zone_lookup.csv\",\n",
    "        header=True,\n",
    "        schema=schema,\n",
    "    )\n",
    "    .createOrReplaceTempView(\"taxi_zones\")\n",
    ")\n",
    "spark.sql(\"SELECT * FROM taxi_zones\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|PUlocationID|count|\n",
      "+------------+-----+\n",
      "|           2|    1|\n",
      "|         105|    2|\n",
      "|         111|    5|\n",
      "|          30|    8|\n",
      "|         120|   14|\n",
      "|          12|   15|\n",
      "|         207|   23|\n",
      "|          27|   25|\n",
      "|         154|   26|\n",
      "|           8|   29|\n",
      "|         128|   39|\n",
      "|         253|   47|\n",
      "|          96|   53|\n",
      "|          34|   57|\n",
      "|          59|   62|\n",
      "|          58|   77|\n",
      "|          99|   89|\n",
      "|         190|   98|\n",
      "|          54|  105|\n",
      "|         217|  110|\n",
      "+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fhv.groupBy(\"PUlocationID\")\n",
    "    .count()\n",
    "    .orderBy(\"count\")\n",
    "    .createOrReplaceTempView(\"pickup_loc_freq\") \n",
    ")\n",
    "spark.sql(\"SELECT * FROM pickup_loc_freq\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+------------+-----+\n",
      "|LocationID|      Borough|                Zone|service_zone|PUlocationID|count|\n",
      "+----------+-------------+--------------------+------------+------------+-----+\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|           2|    1|\n",
      "|       105|    Manhattan|Governor's Island...| Yellow Zone|         105|    2|\n",
      "|       111|     Brooklyn| Green-Wood Cemetery|   Boro Zone|         111|    5|\n",
      "|        30|       Queens|       Broad Channel|   Boro Zone|          30|    8|\n",
      "|       120|    Manhattan|     Highbridge Park|   Boro Zone|         120|   14|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|          12|   15|\n",
      "|       207|       Queens|Saint Michaels Ce...|   Boro Zone|         207|   23|\n",
      "|        27|       Queens|Breezy Point/Fort...|   Boro Zone|          27|   25|\n",
      "|       154|     Brooklyn|Marine Park/Floyd...|   Boro Zone|         154|   26|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|           8|   29|\n",
      "|       128|    Manhattan|    Inwood Hill Park|   Boro Zone|         128|   39|\n",
      "|       253|       Queens|       Willets Point|   Boro Zone|         253|   47|\n",
      "|        96|       Queens|Forest Park/Highl...|   Boro Zone|          96|   53|\n",
      "|        34|     Brooklyn|  Brooklyn Navy Yard|   Boro Zone|          34|   57|\n",
      "|        59|        Bronx|        Crotona Park|   Boro Zone|          59|   62|\n",
      "|        58|        Bronx|        Country Club|   Boro Zone|          58|   77|\n",
      "|        99|Staten Island|     Freshkills Park|   Boro Zone|          99|   89|\n",
      "|       190|     Brooklyn|       Prospect Park|   Boro Zone|         190|   98|\n",
      "|        54|     Brooklyn|     Columbia Street|   Boro Zone|          54|  105|\n",
      "|       217|     Brooklyn|  South Williamsburg|   Boro Zone|         217|  110|\n",
      "+----------+-------------+--------------------+------------+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if TYPE_CHECKING:\n",
    "    from pyspark.sql import DataFrame\n",
    "\n",
    "\n",
    "taxi_zones_extended: \"DataFrame\" = spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM taxi_zones\n",
    "    JOIN pickup_loc_freq\n",
    "        ON LocationID = PUlocationID\n",
    "    ORDER BY count;\n",
    "\"\"\")\n",
    "taxi_zones_extended.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q6 Answer: The name of the LEAST frequent pickup location Zone is Jamaica Bay\n"
     ]
    }
   ],
   "source": [
    "least_freq_zone: str = taxi_zones_extended.first()[\"Zone\"]\n",
    "print(\"Q6 Answer: The name of the LEAST frequent pickup location Zone is {}\".format(least_freq_zone))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry-demo-a5Dmt_lL-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
